{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_funcs import search_tweets_to_db, user_tweets_to_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to pull roughly 1000 tweets for each query listed in the database. We have 105 queries each plus a handful of twitter accounts we have found that post only funny tweets. When using the search function, the number of tweets added to the database is usually a lot less than the number pulled. This is a result of deleting duplicate tweets that are either multiple retweets of the same tweet or already in the database. The functions ensure that there are no duplicates so there is no need to worry about using similar queries such as 'horses' and '#horses'. Try to get roughly 1000 tweets using as few or as many queries as you need and feel free to skip or only pull a few hundred tweets for some of the really weird topics. Queries don't need to exactly match the topics. Don't forget to change the label accordingly especially when pulling from the user accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions `user_tweets_to_db` and `search_tweets_to_db` retrieve tweets from Twitter's API, format them using Pandas, and insert them into the database using SQLAlchemy's ORM. Both functions have the same parameters:\n",
    "- `query` - Either the string query or the user's handle depending on the function used\n",
    "- `label` - 1 if the tweets are funny, 0 if they are not\n",
    "- `count` - The number of tweets to retrieve. 90000 and 18000 max for user and search tweets respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving 500 tweets from crime film...\n",
      "Tweets retrieved. Formatting...\n",
      "Tweets formatted. Filtering tweets...\n",
      "Tweets filtered. Posting to database...\n",
      "130 tweets added database in 16.683929204940796 s\n",
      "You can pull 16100 more search tweets in the next 13 min 18 sec\n"
     ]
    }
   ],
   "source": [
    "# Either a group of words 'playstation 5', a single word 'election', or a hashtag '#joke'\n",
    "query = 'crime film'\n",
    "# 1 if funny, 0 if not funny\n",
    "label = 0\n",
    "# TBD\n",
    "count = 500\n",
    "search_tweets_to_db(query, label, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving 90000 tweets from @dadjokeman...\n",
      "Tweets retrieved. Formatting...\n",
      "Tweets formatted. Filtering tweets...\n",
      "Tweets filtered. Posting to database...\n",
      "2951 tweets added database in 223.85237216949463 s\n",
      "You can pull 86600 more user tweets in the next 11 min 15 sec\n"
     ]
    }
   ],
   "source": [
    "# A twitter handle without the @ \n",
    "query = 'dadjokeman'\n",
    "# 1 if funny, 0 if not funny\n",
    "label = 1\n",
    "# Just use 90000 and it will collect all of that users tweets even if they don't have that many\n",
    "count = 90000\n",
    "a = user_tweets_to_db(query, label, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
